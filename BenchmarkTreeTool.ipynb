{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2021 porteratzo\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import treetool.utils as utils\n",
    "import treetool.tree_tool as tree_tool\n",
    "import treetool.seg_tree as seg_tree\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluationMetrics = {}\n",
    "\n",
    "EvaluationMetrics['Completeness'] = []\n",
    "EvaluationMetrics['Correctness'] = []\n",
    "EvaluationMetrics['Mean_AoD'] = []\n",
    "EvaluationMetrics['Diameter_RMSE'] = []\n",
    "EvaluationMetrics['Diameter_RMSE_E'] = []\n",
    "EvaluationMetrics['Diameter_RMSE_C'] = []\n",
    "EvaluationMetrics['Diameter_bias'] = []\n",
    "EvaluationMetrics['Location_RMSE'] = []\n",
    "EvaluationMetrics['Location_bias'] = []\n",
    "\n",
    "EvaluationMetrics['Relative_Diameter_RMSE'] = []\n",
    "EvaluationMetrics['Relative_Diameter_bias'] = []\n",
    "EvaluationMetrics['Relative_Location_RMSE'] = []\n",
    "EvaluationMetrics['Relative_Location_bias'] = []\n",
    "\n",
    "EvaluationMetrics['n_ref'] = []\n",
    "EvaluationMetrics['n_match'] = []\n",
    "EvaluationMetrics['n_extr'] = []\n",
    "EvaluationMetrics['location_y'] = []\n",
    "EvaluationMetrics['diameter_y'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mysegmentor = tree_tool.treetool()\n",
    "\n",
    "for number in range(1,7):\n",
    "    print('load point cloud ', number)\n",
    "    file_directory = f\"data/downsampledlesscloudEURO{number}.pcd\"\n",
    "    PointCloud = o3d.io.read_point_cloud(file_directory)\n",
    "\n",
    "    PointCloudV = seg_tree.voxelize(PointCloud,0.06)\n",
    "    Mysegmentor.point_cloud = tree_tool.set_point_cloud(PointCloudV)\n",
    "    Mysegmentor.full_process(verticality_threshold=0.04,\n",
    "    curvature_threshold=0.1,\n",
    "    tolerance=1,\n",
    "    min_cluster_size=40,\n",
    "    max_cluster_size=6000000,\n",
    "    max_distance=0.4,\n",
    "    lowstems_height=5,\n",
    "    cutstems_height=5,\n",
    "    search_radius=0.08,\n",
    "    searchRadius_cylinder=0.1)\n",
    "    #####################################################\n",
    "    print('Get ground truth')\n",
    "    treedata = pd.read_csv('data/TLS_Benchmarking_Plot_' + str(number) + '_LHD.txt',sep = '\\t',names = ['x','y','height','DBH'])\n",
    "    Xcor,Ycor,diam = treedata.iloc[0,[0,1,3]]\n",
    "    Zcor = 0\n",
    "    TreeDict = [np.array([Xcor,Ycor,diam])]\n",
    "    for i,rows in treedata.iloc[1:].iterrows():\n",
    "        Xcor,Ycor,diam = rows.iloc[[0,1,3]]\n",
    "        if not np.any(np.isnan([Xcor,Ycor,diam])):\n",
    "            TreeDict.append(np.array([Xcor,Ycor,diam]))\n",
    "\n",
    "                #DataBase\n",
    "    #Found trees\n",
    "    #Hungarian Algorithm assignment\n",
    "    CostMat = np.ones([len(TreeDict),len(Mysegmentor.visualization_cylinders)])\n",
    "    for X,datatree in enumerate(TreeDict):\n",
    "        for Y,foundtree in enumerate(Mysegmentor.finalstems):\n",
    "            CostMat[X,Y] = np.linalg.norm([datatree[0:2]-foundtree['model'][0:2]])\n",
    "\n",
    "    dataindex, foundindex = linear_sum_assignment(CostMat,maximize=False)\n",
    "\n",
    "    #Get metrics\n",
    "    locationerror = []\n",
    "    correctlocationerror = []\n",
    "    diametererror = []\n",
    "    diametererrorElipse = []\n",
    "    diametererrorComb = []\n",
    "    for i,j in zip(dataindex, foundindex):\n",
    "        locationerror.append(np.linalg.norm((Mysegmentor.finalstems[j]['model'][0:2]-TreeDict[i][0:2])))\n",
    "        if locationerror[-1]<0.4:\n",
    "            diametererror.append(abs(Mysegmentor.finalstems[j]['model'][6]*2-TreeDict[i][2]))        \n",
    "            correctlocationerror.append(np.linalg.norm((Mysegmentor.finalstems[j]['model'][0:2]-TreeDict[i][0:2])))        \n",
    "            diametererrorElipse.append(abs(Mysegmentor.finalstems[j]['ellipse_diameter']-TreeDict[i][2]))        \n",
    "            mindi = max(Mysegmentor.finalstems[j]['cylinder_diameter'],Mysegmentor.finalstems[j]['ellipse_diameter'])\n",
    "            diametererrorComb.append(abs(mindi-TreeDict[i][2]))\n",
    "        \n",
    "    EvaluationMetrics['n_ref'].append(len(TreeDict))\n",
    "    EvaluationMetrics['n_match'].append(len(diametererror))\n",
    "    EvaluationMetrics['n_extr'].append(len(locationerror) - EvaluationMetrics['n_match'][-1])\n",
    "    EvaluationMetrics['location_y'].append(np.linalg.norm(np.sum(np.array([TreeDict[i][0:2] for i in dataindex]),axis=0)/len(dataindex)))\n",
    "    EvaluationMetrics['diameter_y'].append(np.sum(np.array([Mysegmentor.finalstems[i]['model'][6]*2 for i in foundindex]),axis=0)/len(foundindex))\n",
    "\n",
    "    EvaluationMetrics['Completeness'].append(EvaluationMetrics['n_match'][-1]/EvaluationMetrics['n_ref'][-1])\n",
    "    EvaluationMetrics['Correctness'].append(EvaluationMetrics['n_match'][-1]/(EvaluationMetrics['n_extr'][-1]+EvaluationMetrics['n_match'][-1]))\n",
    "    EvaluationMetrics['Mean_AoD'].append(2*EvaluationMetrics['n_match'][-1]/(EvaluationMetrics['n_ref'][-1]+EvaluationMetrics['n_extr'][-1]))\n",
    "    EvaluationMetrics['Diameter_RMSE'].append(np.sqrt(np.sum(np.array(diametererror)**2)/len(diametererror)))\n",
    "    EvaluationMetrics['Diameter_bias'].append(np.sum(np.array(diametererror))/len(diametererror))\n",
    "    EvaluationMetrics['Location_RMSE'].append(np.sqrt(np.sum(np.array(correctlocationerror)**2)/len(correctlocationerror)))\n",
    "    EvaluationMetrics['Location_bias'].append(np.sum(np.array(correctlocationerror))/len(correctlocationerror))\n",
    "\n",
    "    EvaluationMetrics['Relative_Diameter_RMSE'].append(EvaluationMetrics['Diameter_RMSE'][-1]/EvaluationMetrics['diameter_y'][-1])\n",
    "    EvaluationMetrics['Relative_Diameter_bias'].append(EvaluationMetrics['Diameter_bias'][-1]/EvaluationMetrics['diameter_y'][-1])\n",
    "    EvaluationMetrics['Relative_Location_RMSE'].append(EvaluationMetrics['Location_RMSE'][-1]/EvaluationMetrics['location_y'][-1])\n",
    "    EvaluationMetrics['Relative_Location_bias'].append(EvaluationMetrics['Location_bias'][-1]/EvaluationMetrics['location_y'][-1])\n",
    "\n",
    "    EvaluationMetrics['Diameter_RMSE_E'].append(np.sqrt(np.sum(np.array(diametererrorElipse)**2)/len(diametererrorElipse)))\n",
    "    EvaluationMetrics['Diameter_RMSE_C'].append(np.sqrt(np.sum(np.array(diametererrorComb)**2)/len(diametererrorComb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Methods = ['CAF','TUDelft','FGI','IntraIGN','RADI','NJU','Shinshu','SLU','TUZVO','TUWien','RILOG','TreeMetrics','UofL','WHU']\n",
    "CompletenessEasy = [88, 66, 94, 84, 74, 88, 89, 94, 87, 82, 96, 36, 69, 89]\n",
    "CompletenessMedium = [75, 49, 88, 65, 59, 81, 78, 88, 74, 68, 87, 27, 58, 80]\n",
    "CompletenessHard = [44, 16, 66, 27, 25, 45, 46, 64, 39, 39, 63, 18, 37, 52]\n",
    "\n",
    "CorrectnessEasy = [96, 69, 90, 97, 94, 44, 77, 86, 94, 95, 77, 99, 86, 86]\n",
    "CorrectnessMedium = [99, 61, 89, 98, 97, 44, 76, 91, 95, 96, 89, 99, 91, 88]\n",
    "CorrectnessHard = [99, 41, 93, 97, 97, 70, 74, 91, 95, 97, 88, 99, 91, 90]\n",
    "\n",
    "StemRMSEEasy = [2.2, 15.4, 2.8, 1.2, 3.2, 13.2, 5.2, 2.0, 2.0, 1.6, 3.2, 3.0, 8.8, 5.8]\n",
    "StemRMSEMedium = [3.2, 18.2, 3.0, 4.0, 4.8, 20.0, 8.0, 4.2, 3.6, 2.6, 6.4, 2.6, 11.6, 8.2]\n",
    "StemRMSEHard = [4.0, 27.3, 6.4, 7.0, 8.0, 20.0, 12.0, 6.6, 8.2, 4.8, 11.2, 2.4, 14.4, 12.0]\n",
    "\n",
    "DBHRMSEEasy = [2.0, 12.8, 1.4, 1.6, 2.0, 21.0, 4.8, 1.8, 2.2, 1.4, 8.6, 1.2, 6.2, 7.2]\n",
    "DBHRMSEMedium = [2.2, 12.2, 1.8, 3.4, 4.0, 24.0, 8.0, 3.2, 3.4, 1.6, 11.0, 2.0, 8.4, 9.6]\n",
    "DBHRMSEHard = [1.8, 17.4, 2.0, 30.0, 7.4, 25.0, 9.4, 3.0, 3.6, 1.2, 17.4, 2.4, 9.4, 12.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BenchmarkMetrics = {}\n",
    "BenchmarkMetrics['Completeness'] = [CompletenessEasy,CompletenessMedium,CompletenessHard]\n",
    "BenchmarkMetrics['Correctness'] = [CorrectnessEasy,CorrectnessMedium,CorrectnessHard]\n",
    "BenchmarkMetrics['Location_RMSE'] = [StemRMSEEasy,StemRMSEMedium,StemRMSEHard]\n",
    "BenchmarkMetrics['Diameter_RMSE'] = [DBHRMSEEasy,DBHRMSEMedium,DBHRMSEHard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    np.savez('resultsFGIElipse',\n",
    "             n_ref =EvaluationMetrics['n_ref'],\n",
    "             n_match =EvaluationMetrics['n_match'],\n",
    "             n_extr =EvaluationMetrics['n_extr'],\n",
    "             location_y =EvaluationMetrics['location_y'],\n",
    "             diameter_y =EvaluationMetrics['diameter_y'],\n",
    "             Completeness =EvaluationMetrics['Completeness'],\n",
    "                    Correctness =EvaluationMetrics['Correctness'],\n",
    "                    Mean_AoD =EvaluationMetrics['Mean_AoD'],\n",
    "                    Diameter_RMSE =EvaluationMetrics['Diameter_RMSE'],\n",
    "                    Diameter_bias =EvaluationMetrics['Diameter_bias'],\n",
    "                    Location_RMSE =EvaluationMetrics['Location_RMSE'],\n",
    "                    Location_bias =EvaluationMetrics['Location_bias'],\n",
    "                    Relative_Diameter_RMSE =EvaluationMetrics['Relative_Diameter_RMSE'],\n",
    "                    Relative_Diameter_bias =EvaluationMetrics['Relative_Diameter_bias'],\n",
    "                    Relative_Location_RMSE =EvaluationMetrics['Relative_Location_RMSE'],\n",
    "                    Relative_Location_bias =EvaluationMetrics['Relative_Location_bias'],\n",
    "            Diameter_RMSE_E = EvaluationMetrics['Diameter_RMSE_E'],\n",
    "    Diameter_RMSE_C = EvaluationMetrics['Diameter_RMSE_C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(EvaluationMetrics['Diameter_RMSE_C']), np.mean(EvaluationMetrics['Diameter_RMSE_E']), np.mean(EvaluationMetrics['Diameter_RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    fileFGI = np.load('resultsFGIElipse.npz')\n",
    "\n",
    "    alldata = ['n_ref', 'n_match', 'n_extr', 'Completeness', 'Correctness', 'Diameter_RMSE', 'Diameter_bias', \n",
    "               'Location_RMSE', 'Location_bias', 'Relative_Diameter_RMSE', 'Relative_Diameter_bias', 'Relative_Location_RMSE', 'Relative_Location_bias','Diameter_RMSE_C','Diameter_RMSE_E']\n",
    "\n",
    "    EvaluationMetrics = {}\n",
    "    for i in alldata:\n",
    "        EvaluationMetrics[i] = fileFGI[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = len(Methods[0:3] + ['our_imp'] + Methods[3:])\n",
    "colors = cm.gist_rainbow(np.arange(si)/si)[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.randint(0,255,size = (len(Methods[0:3] + ['our_imp'] + ['our_imp_2'] + Methods[3:]),3))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors = np.random.randint(0,255,size = (len(Methods[0:3] + ['our_imp'] + ['our_imp_2'] + Methods[3:]),3))/255\n",
    "colors = plt.cm.jet(np.linspace(0,0.99,len(Methods[0:3] + ['our_imp'] + ['our_imp_2'] + Methods[3:])))\n",
    "colors = [0.5*color if 'our_imp' not in name else (1.,0.,0.) for name, color in  zip(Methods[0:3] + ['our_imp'] + ['our_imp_2'] + Methods[3:], colors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluationMetrics2 = EvaluationMetrics.copy()\n",
    "EvaluationMetrics2['Diameter_RMSE'] = EvaluationMetrics2['Diameter_RMSE_C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = ['Completeness', 'Correctness']\n",
    "dificulties = ['easy', 'medium', 'hard']\n",
    "plt.figure(figsize=(16,46))\n",
    "for n,i in enumerate(alldata):\n",
    "    for n2 in range(3):\n",
    "        plt.subplot(12,1,n*3+n2+1)\n",
    "        plt.title(i + ' ' + dificulties[n2])\n",
    "        mine = np.mean(EvaluationMetrics[i][slice(n2,n2+2)])*100\n",
    "        mine2 = np.mean(EvaluationMetrics2[i][slice(n2,n2+2)])*100\n",
    "        #colors=['black', 'red', 'green', 'blue', 'cyan', 'magenta', 'yellow','black', 'red', 'green', 'blue', 'cyan', 'magenta', 'yellow']\n",
    "        sortstuff = sorted(zip(Methods[0:3] + ['our_imp'] + ['our_imp_2'] + Methods[3:],BenchmarkMetrics[i][n2][0:3] + [mine] + [mine2] + BenchmarkMetrics[i][n2][3:],colors),key=lambda x:x[1])\n",
    "        sortmethods = [i[0] for i in sortstuff]\n",
    "        sortnum = [i[1] for i in sortstuff]\n",
    "        sortcol = [i[2] for i in sortstuff]\n",
    "        #plt.bar(np.arange(len(BenchmarkMetrics[i][n2])+1),BenchmarkMetrics[i][n2]+[mine])\n",
    "        plt.bar(sortmethods, sortnum\n",
    "                , color = sortcol, width = 0.2)\n",
    "        plt.tight_layout(pad=3.0)\n",
    "        plt.xticks(rotation=30, fontsize=18)\n",
    "        plt.grid(axis='y')\n",
    "plt.savefig('metricsnew.pdf',pad_inches = 0.1, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = ['Location_RMSE', 'Diameter_RMSE']\n",
    "dificulties = ['easy', 'medium', 'hard']\n",
    "plt.figure(figsize=(16,46))\n",
    "for n,i in enumerate(alldata):\n",
    "    for n2 in range(3):\n",
    "        plt.subplot(12,1,n*3+n2+1)\n",
    "        plt.title(i + ' ' + dificulties[n2])\n",
    "        mine = np.mean(EvaluationMetrics[i][slice(n2,n2+2)])*100\n",
    "        mine2 = np.mean(EvaluationMetrics2[i][slice(n2,n2+2)])*100\n",
    "        #colors=['black', 'red', 'green', 'blue', 'cyan', 'magenta', 'yellow','black', 'red', 'green', 'blue', 'cyan', 'magenta', 'yellow']\n",
    "        sortstuff = sorted(zip(Methods[0:3] + ['our_imp'] + ['our_imp_2'] + Methods[3:],BenchmarkMetrics[i][n2][0:3] + [mine] + [mine2] + BenchmarkMetrics[i][n2][3:],colors),key=lambda x:x[1])\n",
    "        sortmethods = [i[0] for i in sortstuff]\n",
    "        sortnum = [i[1] for i in sortstuff]\n",
    "        sortcol = [i[2] for i in sortstuff]\n",
    "        #plt.bar(np.arange(len(BenchmarkMetrics[i][n2])+1),BenchmarkMetrics[i][n2]+[mine])\n",
    "        plt.bar(sortmethods, sortnum\n",
    "                , color = sortcol, width = 0.2)\n",
    "        plt.tight_layout(pad=3.0)\n",
    "        plt.grid(axis='y')\n",
    "        plt.xticks(rotation=30, fontsize=18)\n",
    "plt.savefig('metricsnew2.pdf',pad_inches = 0.1, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eef1813aaf8490bb538b4cefa09c4a5c277a5aca32480f7ba29942be734d8dc0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('tree': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
